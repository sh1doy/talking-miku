{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shido/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# imports(default)\n",
    "import sys\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gensim\n",
    "import MeCab\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.optimizers import *\n",
    "keras = tf.keras\n",
    "sys.path.append(\"../\")\n",
    "from models import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_files = glob(\"../dataset/charactor/*.txt\")\n",
    "conv_files = glob(\"../dataset/conversation/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_texts = [read_file(file) for file in char_files]\n",
    "conv_texts = [read_file(file) for file in conv_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = Parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for conv in conv_texts:\n",
    "    for line in conv:\n",
    "        vocab = vocab.union(set(parser.parse(line)))\n",
    "for conv in char_texts:\n",
    "    for line in conv:\n",
    "        vocab = vocab.union(set(parser.parse(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2id = {}\n",
    "id2word = {}\n",
    "\n",
    "for e, word in enumerate([\"<PAD>\", \"<BOS>\", \"<EOS>\", \"<UNK>\"] + sorted(list(vocab))):\n",
    "    word2id[word] = e\n",
    "    id2word[e] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(word2id, id2word)\n",
    "char_seqs = [[tokenizer.encode(parser.parse(line)) for line in text] for text in char_texts]\n",
    "conv_seqs = [[tokenizer.encode(parser.parse(line)) for line in text] for text in conv_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 200\n",
    "NUM_UNITS = 400\n",
    "SEQ_LEN = 150\n",
    "BEAM_WIDTH = 3\n",
    "BATCH_SIZE = 256\n",
    "VOCAB = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_conv = []\n",
    "for text in conv_seqs:\n",
    "    clf_conv += text[1::2]\n",
    "clf_char = []\n",
    "for text in char_seqs:\n",
    "    clf_char += text\n",
    "clf_x = pad_sequences(clf_char + clf_conv, SEQ_LEN)\n",
    "clf_y = [1 for _ in clf_char] + [0 for _ in clf_conv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier(EMBEDDING_SIZE, NUM_UNITS, VOCAB)\n",
    "for layer in clf.clf_model.layers:\n",
    "    layer.trainable = False\n",
    "    layer.supports_masking = True\n",
    "clf.model.load_weights(\"../models/clf.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharacterizingAutoencoder:\n",
    "    def __init__(self, clf, EMBEDDING_SIZE, NUM_UNITS, SEQ_LEN, BEAM_WIDTH, BATCH_SIZE, VOCAB):\n",
    "        encoder_inputs = Input([None], dtype=\"int32\", name=\"x\")\n",
    "        E_embed = Embedding(VOCAB, EMBEDDING_SIZE, mask_zero=True, name=\"E_embed\")(encoder_inputs)\n",
    "        encoder1 = LSTM(NUM_UNITS, return_state=True, return_sequences=True, dropout=.2, recurrent_dropout=.2)\n",
    "        encoder2 = LSTM(NUM_UNITS, return_state=True, dropout=.2, recurrent_dropout=.2)\n",
    "        out, *mid_states1 = encoder1(E_embed)\n",
    "        out, *mid_states2 = encoder2(out)\n",
    "        # End2end learning\n",
    "        decoder_inputs = Input(shape=[None], dtype=\"int32\", name=\"y_\")\n",
    "        F_embed = Embedding(VOCAB, EMBEDDING_SIZE, mask_zero=True, name=\"F_embed\")(decoder_inputs)\n",
    "        decoder1 = LSTM(NUM_UNITS, return_sequences=True, return_state=True, dropout=.2, recurrent_dropout=.2)\n",
    "        decoder2 = LSTM(NUM_UNITS, return_sequences=True, return_state=True, dropout=.2, recurrent_dropout=.2)\n",
    "        decoder_outputs, *decoder_states1 = decoder1(F_embed, initial_state=mid_states1)\n",
    "        decoder_outputs, *decoder_states2 = decoder2(decoder_outputs, initial_state=mid_states2)\n",
    "        decoder_dense = Dense(VOCAB, activation='softmax', name=\"output_dense\")\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        \n",
    "        mikulity = clf.clf_model(decoder_outputs)\n",
    "\n",
    "        self.training_model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=[decoder_outputs, mikulity])\n",
    "        # Single Encoder\n",
    "        self.encoder_model = Model(inputs=encoder_inputs, outputs=mid_states1 + mid_states2)\n",
    "        # Single Decoder\n",
    "        decoder_states = [Input([NUM_UNITS]) for _ in range(4)]\n",
    "        d_out, *new_decoder_states1 = decoder1(F_embed, initial_state=decoder_states[0:2])\n",
    "        d_out, *new_decoder_states2 = decoder2(d_out, initial_state=decoder_states[2:4])\n",
    "        new_decoder_outputs = decoder_dense(d_out)\n",
    "\n",
    "        self.decoder_model = Model(inputs=[decoder_inputs] + decoder_states,\n",
    "                                   outputs=[new_decoder_outputs] + new_decoder_states1 + new_decoder_states2)\n",
    "\n",
    "        self.training_model.compile(Adam(1e-3), loss='sparse_categorical_crossentropy')\n",
    "\n",
    "    # generate target given source sequence\n",
    "    def predict_sequence(self, source, n_steps, mode=\"greedy\", alpha=1.0):\n",
    "        # encode\n",
    "        state = self.encoder_model.predict(source)\n",
    "        # start of sequence input\n",
    "        x = np.array([[1] for _ in range(len(source))])\n",
    "        # collect predictions\n",
    "        output = list()\n",
    "        for t in range(n_steps):\n",
    "            # predict next char\n",
    "            x, *state = self.decoder_model.predict([x] + state)\n",
    "            if mode == \"greedy\":\n",
    "                x = x.argmax(-1)\n",
    "            elif mode == \"random\":\n",
    "                next_x = []\n",
    "                for i in range(len(x)):\n",
    "                    x[np.isnan(x)] = 0.0\n",
    "                    p = np.power(x[i][0], alpha)\n",
    "                    p /= p.sum()\n",
    "                    next_x.append(np.random.choice(np.arange(len(x[i][0])), p=p))\n",
    "                x = np.array(next_x)[:, np.newaxis]\n",
    "            # store prediction\n",
    "            output.append(x)\n",
    "            # update target sequence\n",
    "        return np.concatenate(output, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"output_dense_6/truediv:0\", shape=(?, ?, 5753), dtype=float32)\n",
      "<tensorflow.python.keras._impl.keras.engine.input_layer.InputLayer object at 0x7fa110b4b128>\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x7fa110b4b0b8>\n",
      "<tensorflow.python.keras._impl.keras.layers.recurrent.LSTM object at 0x7fa110b5e748>\n",
      "<tensorflow.python.keras._impl.keras.layers.core.Dense object at 0x7fa110b26da0>\n",
      "Tensor(\"model_15/y_1/Sigmoid:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "autoencoder = CharacterizingAutoencoder(clf, EMBEDDING_SIZE, NUM_UNITS, SEQ_LEN, BEAM_WIDTH, BATCH_SIZE, VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.supports_masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
